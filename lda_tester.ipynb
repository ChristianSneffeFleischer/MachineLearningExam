{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester notebook for the LDA dimensionality reduction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature extraction (PCA)\n",
    "# from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "# from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "trainDataNP = np.load(\"fashion_train.npy\")\n",
    "testDataNP = np.load(\"fashion_test.npy\")\n",
    "\n",
    "# Split data into X and y arrays\n",
    "X_train = trainDataNP[:, :-1]\n",
    "y_train = trainDataNP[:, -1]\n",
    "X_test = testDataNP[:, :-1]\n",
    "y_test = testDataNP[:, -1]\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LDA class\n",
    "\n",
    "class LDA:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.class_labels = np.unique(y_train)\n",
    "        self.coeffs, self.constants = self.compute_coeffs_and_constants()\n",
    "        return self\n",
    "\n",
    "    def compute_class_stats(self, class_label):\n",
    "        '''Compute class specific statistics.'''\n",
    "        class_data = self.X_train[self.y_train == class_label]\n",
    "        class_sample_mean = np.mean(class_data, axis = 0)\n",
    "        class_sample_var = np.var(class_data, axis = 0)\n",
    "        class_sample_prior = np.sum(self.y_train == class_label) / len(self.y_train)\n",
    "        return class_sample_mean, class_sample_var, class_sample_prior\n",
    "\n",
    "    def compute_coeffs_and_constants(self):\n",
    "        '''Compute coefficients and constants for each class.'''\n",
    "        coeffs = {} # Initialize empty dictionary for coefficients\n",
    "        constants = {} # Initialize empty dictionary for constants\n",
    "        epsilon = 1e-12 # Small constant to avoid division by zero\n",
    "\n",
    "        # Iterate over each class\n",
    "        for class_label in self.class_labels:\n",
    "\n",
    "            # Get statistics for class\n",
    "            sample_mean, sample_var, sample_prior = self.compute_class_stats(class_label)\n",
    "            \n",
    "            # Compute coefficient\n",
    "            alpha = sample_mean / (sample_var + epsilon)\n",
    "\n",
    "            # Compute constant\n",
    "            beta = -(np.sum(sample_mean**2) / (2 * np.sum(sample_var))) + np.log(sample_prior)\n",
    "\n",
    "            # Record coefficient and constant in dictionaries\n",
    "            coeffs[class_label] = alpha\n",
    "            constants[class_label] = beta\n",
    "\n",
    "        return coeffs, constants\n",
    "\n",
    "    def discriminant(self, X, alpha, beta):\n",
    "        '''Compute the discriminant value for an input value or array X.'''\n",
    "        return np.dot(X, alpha) + beta\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predict class for an input value or array X.'''\n",
    "        # check_is_fitted(self)\n",
    "        # X = check_array(X)\n",
    "\n",
    "        # Compute the discriminant values for each label\n",
    "        discriminants = np.array([self.discriminant(X, self.coeffs[class_label], self.constants[class_label]) for class_label in self.class_labels])\n",
    "        \n",
    "        # Predict classes and add labels\n",
    "        predicted_labels = np.argmax(discriminants, axis = 0)\n",
    "        predicted_classes = np.array(self.class_labels)[predicted_labels]\n",
    "        \n",
    "        return predicted_classes\n",
    "\n",
    "    def transform(self, X, n_components):\n",
    "        '''Project data onto the linear discriminant space.'''\n",
    "        # check_is_fitted(self)\n",
    "        # X = check_array(X)\n",
    "\n",
    "        # Initialize empty array to store projected data\n",
    "        projected_data = np.zeros((len(X), len(self.class_labels)))\n",
    "\n",
    "        # Iterate over each class\n",
    "        for idx, class_label in enumerate(self.class_labels):\n",
    "            # Project data using the pre-computed coefficients and constants\n",
    "            # projected_data[:, idx] = np.dot(X, self.coeffs[class_label]) + self.constants[class_label]\n",
    "\n",
    "            # Compute the discriminant values\n",
    "            discriminants = self.discriminant(X, self.coeffs[class_label], self.constants[class_label])\n",
    "\n",
    "            # Project data using the discriminant value\n",
    "            projected_data[:, idx] = discriminant\n",
    "\n",
    "        return projected_data[:, :n_components]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        '''Compute accuracy for the given input data and labels.'''\n",
    "        # check_is_fitted(self)\n",
    "        # X = check_array(X)\n",
    "        # y = check_array(y)\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.205\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy\n",
    "\n",
    "# Initialize LDA model\n",
    "lda_model = LDA()\n",
    "lda_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "accuracy = lda_model.score(X_test_scaled, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very low.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Multiple Discriminant Analysis (MDA) class which maybe works better\n",
    "# Code is adapted using \n",
    "# Alpaydin, E. (2014). Introduction to Machine Learning. The MIT Press. Section 6.8\n",
    "# and\n",
    "# https://www.csd.uwo.ca/~oveksler/Courses/CS434a_541a/Lecture8.pdf?fbclid=IwAR2txae5XGTwi8Gjo2y9SbwguiJ0SUbLvCBzY0rYq-HOxhfr2MAjPo1GG3A\n",
    "\n",
    "class MDA:\n",
    "    def __init__(self, k = 2):\n",
    "        self.k = k # Amount of discriminant variables\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        m = X.shape[1] # Amount of features\n",
    "\n",
    "        # Compute total mean of all samples\n",
    "        mu = np.mean(X, axis = 0)\n",
    "\n",
    "        # Initiate within- and between-class scatter matrices as empty\n",
    "        S_W = np.zeros((m, m))\n",
    "        S_B = np.zeros((m, m))\n",
    "\n",
    "        # Compute within- and between-class scatter matrices by iterating over each class i\n",
    "        for label in class_labels:\n",
    "\n",
    "            X_i = X[y == label] # Matrix of data points for class i\n",
    "            mu_i = np.mean(X_i, axis = 0) # Sample mean of class i\n",
    "\n",
    "            # Update within-class scatter matrix using class observations and mean\n",
    "            # Use transpose first in matrix multiplation to maintain shape of S_W as (m, m)\n",
    "            S_W += np.dot((X_i - mu_i).T, X_i - mu_i)\n",
    "\n",
    "            # Update between-class scatter matrix using amount of samples, as well as class and total means\n",
    "            # Use transpose first in matrix multiplation to maintain shape of S_B as (m, m)\n",
    "            n_i = X_i.shape[0] # Amount of samples in class i\n",
    "            S_B += n_i * np.dot((mu_i - mu).T, mu_i - mu)\n",
    "\n",
    "        # Compute the inverse of the within-class scatter matrix\n",
    "        S_W_inv = np.linalg.inv(S_W)\n",
    "\n",
    "        # Solve the generalized eigenvalue problem\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(np.dot(S_W_inv, S_B))\n",
    "        \n",
    "        # Sort the eigenvalues and eigenvectors in descending order\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[sorted_indices]\n",
    "        eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "        # Select the top k eigenvectors\n",
    "        selected_eigenvectors = eigenvectors[:, :self.k]\n",
    "\n",
    "        # Make sure numbers in eigenvectors are not complex\n",
    "        selected_eigenvectors = np.real(selected_eigenvectors)\n",
    "\n",
    "        # Normalize eigenvectors\n",
    "        normalized_eigenvectors = selected_eigenvectors / np.linalg.norm(selected_eigenvectors, axis = 0)\n",
    "\n",
    "        # Project the data onto the normalized discriminant subspace\n",
    "        X_projected = np.dot(X, normalized_eigenvectors)\n",
    "\n",
    "        return X_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda = MDA()\n",
    "X_projected = mda.fit_transform(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00624132, -0.12107445],\n",
       "       [ 0.08716425,  0.09764791],\n",
       "       [ 0.04659335, -0.05428298],\n",
       "       ...,\n",
       "       [ 0.02451672,  0.15719014],\n",
       "       [ 0.10742126, -0.05401376],\n",
       "       [ 0.0745882 ,  0.03366667]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.56669806, -0.55699892],\n",
       "       [ 5.20026605,  1.0529189 ],\n",
       "       [-1.9471824 , -0.48922497],\n",
       "       ...,\n",
       "       [-0.22086478, -3.5033158 ],\n",
       "       [-1.43054366, -0.89234007],\n",
       "       [ 6.27484131,  0.72650406]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_MDA = LinearDiscriminantAnalysis(n_components = 2)\n",
    "sklearn_MDA.fit(X_train, y_train)\n",
    "sklearn_MDA.transform(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
