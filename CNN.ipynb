{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Scikit Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "trainDataNP = np.load(\"fashion_train.npy\")\n",
    "testDataNP = np.load(\"fashion_test.npy\")\n",
    "\n",
    "# Split data into X and y arrays\n",
    "X_train = trainDataNP[:, :-1]\n",
    "y_train = trainDataNP[:, -1]\n",
    "X_test = testDataNP[:, :-1]\n",
    "y_test = testDataNP[:, -1]\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "batch_size = 64\n",
    "n_classes = len(np.unique(y_train))\n",
    "alpha = 0.001 # Learning rate\n",
    "n_epochs = 100\n",
    "\n",
    "# Create device object to choose whether to run training on CPU or GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define superclass to handle own input datasets\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Convert NumPy array to PIL Image\n",
    "        image = Image.fromarray(self.X[idx])\n",
    "\n",
    "        # Collect image and label in sample dict\n",
    "        sample = {'image': image, 'label': self.y[idx]}\n",
    "\n",
    "        # Use transformer\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformer\n",
    "transformer = transforms.Compose([transforms.Resize((28, 28)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "train_data = CustomDataset(X_train_scaled, y_train, transform = transformer)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel (greyscale), 32 output channels, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3)\n",
    "\n",
    "        # Second convolutional layer: 32 input channel, 32 output channels, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3)\n",
    "\n",
    "        # First pooling layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        # Third convolutional layer: 32, input channels, 64 output channels, 3x3 kernel\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "\n",
    "        # Third convolutional layer: 64, input channels, 64 output channels, 3x3 kernel\n",
    "        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "\n",
    "        # Second pooling layer\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Flatten before passing to fully connected layers\n",
    "        self.fc_input_size = self.calculate_fc_input_size()\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def calculate_fc_input_size(self):\n",
    "        # Dummy input to calculate the size after convolutional layers\n",
    "        x = torch.randn(1, 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        # Flatten before passing to fully connected layers\n",
    "        return x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # First convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten before passing to fully connected layers\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = CNN(n_classes = n_classes)\n",
    "\n",
    "# Set Loss function with criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = alpha, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "# Defnie total_step to ease iteration through batches\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20, Loss: 1.2007768154144287\n",
      "Epoch 2 / 20, Loss: 1.1654188632965088\n",
      "Epoch 3 / 20, Loss: 1.4722650051116943\n",
      "Epoch 4 / 20, Loss: 1.3363670110702515\n",
      "Epoch 5 / 20, Loss: 0.9191613793373108\n",
      "Epoch 6 / 20, Loss: 0.7635058760643005\n",
      "Epoch 7 / 20, Loss: 1.2439160346984863\n",
      "Epoch 8 / 20, Loss: 1.0293141603469849\n",
      "Epoch 9 / 20, Loss: 1.16072416305542\n",
      "Epoch 10 / 20, Loss: 0.737480640411377\n",
      "Epoch 11 / 20, Loss: 1.1014708280563354\n",
      "Epoch 12 / 20, Loss: 0.5376147031784058\n",
      "Epoch 13 / 20, Loss: 0.6332538723945618\n",
      "Epoch 14 / 20, Loss: 1.2123373746871948\n",
      "Epoch 15 / 20, Loss: 0.8293539881706238\n",
      "Epoch 16 / 20, Loss: 0.8185349702835083\n",
      "Epoch 17 / 20, Loss: 0.6440213918685913\n",
      "Epoch 18 / 20, Loss: 0.5289050340652466\n",
      "Epoch 19 / 20, Loss: 0.790256679058075\n",
      "Epoch 20 / 20, Loss: 0.551320493221283\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "# Use defined number of epochs to determine amount of iterations to train model on \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    # Load in the data in batches using dataloader object\n",
    "    for batch in train_loader:\n",
    "\n",
    "        # Extract images and labels from the batch\n",
    "        images, labels = batch['image'], batch['label']\n",
    "\n",
    "        # Pass image and label tensors to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Run forward pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Run backwards pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print results\n",
    "    print(f'Epoch {epoch} / {n_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lda import LDA\n",
    "# MDA_4 = LDA(n_components = 4)\n",
    "\n",
    "# X_projected_4 = MDA_4.fit_transform(X_train_scaled, y_train)\n",
    "# X_t_projected_4 = MDA_4.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = MLPClassifier()\n",
    "# cnn.fit(X_projected_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.score(X_projected_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = cnn.predict(X_t_projected_4)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n in range (1,10):\n",
    "#     cnn = MLPClassifier()\n",
    "#     scores = cross_val_score(cnn, X_train, y_train, cv=5)\n",
    "#     print(n, round(np.mean(scores), 4), 'and', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56941cacf15e8b05765996006082865469347c2b4cdce983108d1335de8b4245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
